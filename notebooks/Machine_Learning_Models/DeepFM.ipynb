{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f9a7117-94aa-4aad-9f37-fb98282224e0",
   "metadata": {},
   "source": [
    "- DeepFM\n",
    "\n",
    "- FMの2次項 + Deep部分(MLP)を統合して，手動で特徴交差しなくても深い非線形関係も学習できる強力なモデル．\n",
    "\n",
    "| コンポーネント   | 役割                              |\n",
    "| --------- | ------------------------------- |\n",
    "| **線形項**   | 通常の線形回帰（Wideに相当）                |\n",
    "| **FM項**   | 2次の特徴交差（Factorization Machines） |\n",
    "| **Deep項** | Embedding後に MLP に通す（Deep部分）     |\n",
    "| **出力**    | 全部を結合して最終的に1つのスコアを出す（sigmoid）   |\n",
    "\n",
    "- 実装手順\n",
    "- データ前処理(One-Hot-Encoding or IDベース)\n",
    "- Embeddingレイヤー作成\n",
    "- FM2次項の内積計算\n",
    "- MLP(Deep部分)の定義\n",
    "- 結合→出力→学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b53ee0e6-aeae-453e-9a0c-6ae7286501fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# データ読み込み\n",
    "cols = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df = pd.read_csv('u.data', sep='\\t', names=cols)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Leave-One-Out分割\n",
    "df['rank'] = df.groupby('user_id')['timestamp'].rank(method='first', ascending=False)\n",
    "train_df = df[df['rank'] > 1].copy()\n",
    "test_df = df[df['rank'] == 1].copy()\n",
    "\n",
    "# IDを数値に変換\n",
    "user_enc = LabelEncoder()\n",
    "item_enc = LabelEncoder()\n",
    "train_df['user'] = user_enc.fit_transform(train_df['user_id'])\n",
    "train_df['item'] = item_enc.fit_transform(train_df['item_id'])\n",
    "test_df = test_df[test_df['user_id'].isin(user_enc.classes_)]\n",
    "test_df = test_df[test_df['item_id'].isin(item_enc.classes_)]\n",
    "test_df['user'] = user_enc.transform(test_df['user_id'])\n",
    "test_df['item'] = item_enc.transform(test_df['item_id'])\n",
    "\n",
    "# ラベル（クリック or 高評価）\n",
    "train_df['label'] = (train_df['rating'] >= 4).astype(int)\n",
    "test_df['label'] = (test_df['rating'] >= 4).astype(int)\n",
    "\n",
    "num_users = train_df['user'].nunique()\n",
    "num_items = train_df['item'].nunique()\n",
    "\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "302156bd-75f7-42c2-8a5a-85f40f4d161d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FM_Dataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.users = torch.LongTensor(df['user'].values)\n",
    "        self.items = torch.LongTensor(df['item'].values)\n",
    "        self.labels = torch.FloatTensor(df['label'].values)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.users[idx], self.items[idx], self.labels[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3b27452-b372-4d66-8855-f3ba2ff384cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class DeepFM(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim=16, hidden_dims=[32, 16]):\n",
    "        super(DeepFM, self).__init__()\n",
    "        # Embedding\n",
    "        self.user_embed = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embed = nn.Embedding(num_items, embedding_dim)\n",
    "\n",
    "        # 線形項\n",
    "        self.linear_user = nn.Embedding(num_users, 1)\n",
    "        self.linear_item = nn.Embedding(num_items, 1)\n",
    "\n",
    "        # Deep部分\n",
    "        self.deep_input_dim = embedding_dim * 2\n",
    "        layers = []\n",
    "        input_dim = self.deep_input_dim\n",
    "        for h in hidden_dims:\n",
    "            layers.append(nn.Linear(input_dim, h))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = h\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "\n",
    "        # 出力\n",
    "        self.final_linear = nn.Linear(1 + 1 + hidden_dims[-1], 1)\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        # Embedding\n",
    "        u_emb = self.user_embed(user)\n",
    "        i_emb = self.item_embed(item)\n",
    "\n",
    "        # 線形項\n",
    "        linear_part = self.linear_user(user) + self.linear_item(item)\n",
    "\n",
    "        # FM 2次項：<u_emb, i_emb>\n",
    "        fm_part = torch.sum(u_emb * i_emb, dim=1, keepdim=True)\n",
    "\n",
    "        # Deep部分\n",
    "        deep_input = torch.cat([u_emb, i_emb], dim=1)\n",
    "        deep_out = self.mlp(deep_input)\n",
    "\n",
    "        # 出力\n",
    "        concat = torch.cat([linear_part, fm_part, deep_out], dim=1)\n",
    "        out = torch.sigmoid(self.final_linear(concat)).squeeze(1)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21252f87-fbe0-402b-a41b-ab7d192fdd0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 535.2153\n",
      "Epoch 2 Loss: 495.1932\n",
      "Epoch 3 Loss: 463.0873\n",
      "Epoch 4 Loss: 445.1308\n",
      "Epoch 5 Loss: 434.4732\n",
      "Epoch 6 Loss: 427.6331\n",
      "Epoch 7 Loss: 422.2981\n",
      "Epoch 8 Loss: 418.0742\n",
      "Epoch 9 Loss: 414.9157\n",
      "Epoch 10 Loss: 412.2711\n",
      "Epoch 11 Loss: 409.5938\n",
      "Epoch 12 Loss: 407.2626\n",
      "Epoch 13 Loss: 404.8838\n",
      "Epoch 14 Loss: 402.4906\n",
      "Epoch 15 Loss: 400.5358\n",
      "Epoch 16 Loss: 398.4673\n",
      "Epoch 17 Loss: 396.3944\n",
      "Epoch 18 Loss: 394.3774\n",
      "Epoch 19 Loss: 392.0106\n",
      "Epoch 20 Loss: 389.9773\n",
      "Epoch 21 Loss: 387.6903\n",
      "Epoch 22 Loss: 385.5766\n",
      "Epoch 23 Loss: 383.2103\n",
      "Epoch 24 Loss: 381.3129\n",
      "Epoch 25 Loss: 379.4293\n",
      "Epoch 26 Loss: 376.9597\n",
      "Epoch 27 Loss: 374.6642\n",
      "Epoch 28 Loss: 372.7654\n",
      "Epoch 29 Loss: 370.6815\n",
      "Epoch 30 Loss: 368.3481\n",
      "Epoch 31 Loss: 366.3197\n",
      "Epoch 32 Loss: 364.1278\n",
      "Epoch 33 Loss: 362.2289\n",
      "Epoch 34 Loss: 359.9002\n",
      "Epoch 35 Loss: 358.0486\n",
      "Epoch 36 Loss: 355.9696\n",
      "Epoch 37 Loss: 354.2663\n",
      "Epoch 38 Loss: 352.0190\n",
      "Epoch 39 Loss: 349.9987\n",
      "Epoch 40 Loss: 348.0459\n",
      "Epoch 41 Loss: 346.2574\n",
      "Epoch 42 Loss: 344.2243\n",
      "Epoch 43 Loss: 342.1404\n",
      "Epoch 44 Loss: 340.6195\n",
      "Epoch 45 Loss: 338.6319\n",
      "Epoch 46 Loss: 336.7577\n",
      "Epoch 47 Loss: 335.0418\n",
      "Epoch 48 Loss: 332.8972\n",
      "Epoch 49 Loss: 331.5380\n",
      "Epoch 50 Loss: 329.6515\n",
      "Epoch 51 Loss: 327.8187\n",
      "Epoch 52 Loss: 326.3699\n",
      "Epoch 53 Loss: 324.4216\n",
      "Epoch 54 Loss: 322.7646\n",
      "Epoch 55 Loss: 321.1601\n",
      "Epoch 56 Loss: 319.6123\n",
      "Epoch 57 Loss: 318.1776\n",
      "Epoch 58 Loss: 316.6454\n",
      "Epoch 59 Loss: 315.0380\n",
      "Epoch 60 Loss: 313.8681\n",
      "Epoch 61 Loss: 312.4455\n",
      "Epoch 62 Loss: 310.8961\n",
      "Epoch 63 Loss: 309.4728\n",
      "Epoch 64 Loss: 307.6763\n",
      "Epoch 65 Loss: 306.7145\n",
      "Epoch 66 Loss: 305.2917\n",
      "Epoch 67 Loss: 303.7507\n",
      "Epoch 68 Loss: 302.8343\n",
      "Epoch 69 Loss: 301.1067\n",
      "Epoch 70 Loss: 299.8611\n",
      "Epoch 71 Loss: 298.9316\n",
      "Epoch 72 Loss: 297.8771\n",
      "Epoch 73 Loss: 296.4157\n",
      "Epoch 74 Loss: 295.3909\n",
      "Epoch 75 Loss: 294.2086\n",
      "Epoch 76 Loss: 293.0705\n",
      "Epoch 77 Loss: 291.3837\n",
      "Epoch 78 Loss: 290.8888\n",
      "Epoch 79 Loss: 289.3106\n",
      "Epoch 80 Loss: 288.3154\n",
      "Epoch 81 Loss: 287.1970\n",
      "Epoch 82 Loss: 286.0629\n",
      "Epoch 83 Loss: 285.0884\n",
      "Epoch 84 Loss: 284.2200\n",
      "Epoch 85 Loss: 282.9249\n",
      "Epoch 86 Loss: 281.7769\n",
      "Epoch 87 Loss: 280.8048\n",
      "Epoch 88 Loss: 279.8111\n",
      "Epoch 89 Loss: 278.8177\n",
      "Epoch 90 Loss: 277.7453\n",
      "Epoch 91 Loss: 277.0119\n",
      "Epoch 92 Loss: 275.7500\n",
      "Epoch 93 Loss: 274.9671\n",
      "Epoch 94 Loss: 274.4295\n",
      "Epoch 95 Loss: 272.8572\n",
      "Epoch 96 Loss: 272.4507\n",
      "Epoch 97 Loss: 271.2606\n",
      "Epoch 98 Loss: 270.6599\n",
      "Epoch 99 Loss: 269.7294\n",
      "Epoch 100 Loss: 269.0978\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_dataset = FM_Dataset(train_df)\n",
    "test_dataset = FM_Dataset(test_df)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = DeepFM(num_users, num_items).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 学習ループ\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for users, items, labels in train_loader:\n",
    "        users, items, labels = users.to(device), items.to(device), labels.to(device)\n",
    "        preds = model(users, items)\n",
    "        loss = criterion(preds, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1} Loss: {total_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64d684dc-b5ad-4c28-a621-bf8f888e9972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ DeepFM Test Accuracy: 0.6748\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for users, items, labels in test_loader:\n",
    "        users, items = users.to(device), items.to(device)\n",
    "        preds = model(users, items)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "binary_preds = (np.array(all_preds) >= 0.5).astype(int)\n",
    "acc = accuracy_score(all_labels, binary_preds)\n",
    "print(f\"\\n✅ DeepFM Test Accuracy: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "199e77f5-81ee-43b4-9b52-412312d14eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 評価用のスコア生成(正解 + 負例99件)\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "n_negative = 99\n",
    "all_items = set(train_df['item'].unique())\n",
    "user_item_score = defaultdict(list)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for user in test_df['user'].unique():\n",
    "        gt_item = test_df[test_df['user'] == user].iloc[0]['item']\n",
    "        negatives = list(all_items - {gt_item})\n",
    "        sample_size = min(n_negative, len(negatives))\n",
    "        sampled_negatives = np.random.choice(negatives, size=sample_size, replace=False)\n",
    "\n",
    "        # 評価対象アイテム（正解 + 負例）\n",
    "        items_to_score = np.append(sampled_negatives, gt_item)\n",
    "\n",
    "        # Tensor化\n",
    "        user_tensor = torch.LongTensor([user] * len(items_to_score)).to(device)\n",
    "        item_tensor = torch.LongTensor(items_to_score).to(device)\n",
    "\n",
    "        # モデルスコアを出力\n",
    "        scores = model(user_tensor, item_tensor).cpu().numpy()\n",
    "        user_item_score[user] = list(zip(items_to_score, scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9065e8d-d88e-4de0-ad3e-a7a0a55df4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = {\n",
    "    user: [item for item, _ in sorted(items, key=lambda x: x[1], reverse=True)[:10]]\n",
    "    for user, items in user_item_score.items()\n",
    "}\n",
    "\n",
    "ground_truth = {\n",
    "    user: [test_df[test_df['user'] == user].iloc[0]['item']]\n",
    "    for user in user_item_score\n",
    "}\n",
    "\n",
    "# 正解1件だけ取り出す形式に変換\n",
    "gt_single = {u: items[0] for u, items in ground_truth.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bac7b4ac-365a-4a77-8c53-e135013660d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DeepFM モデル評価結果（Top-10）===\n",
      "Recall@10    : 0.0967\n",
      "Precision@10 : 0.0097\n",
      "NDCG@10      : 0.0363\n",
      "MRR@10       : 0.0190\n",
      "Hit@10       : 0.0967\n",
      "=== RecBole モデル評価結果（Top-10）===\n",
      "Recall@10    : 0.0540\n",
      "Precision@10 : 0.0621\n",
      "NDCG@10      : 0.0779\n",
      "MRR@10       : 0.1579\n",
      "Hit@10       : 0.3566\n"
     ]
    }
   ],
   "source": [
    "from Evaluation_index import recall_at_k, precision_at_k, ndcg_at_k, mrr_at_k, hit_at_k\n",
    "\n",
    "# 評価の実行\n",
    "recall = recall_at_k(recommendations, gt_single, 10)\n",
    "precision = precision_at_k(recommendations, gt_single, 10)\n",
    "ndcg = ndcg_at_k(recommendations, gt_single, 10)\n",
    "mrr = mrr_at_k(recommendations, gt_single, 10)\n",
    "hit = hit_at_k(recommendations, gt_single, 10)\n",
    "\n",
    "print(\"=== DeepFM モデル評価結果（Top-10）===\")\n",
    "print(f\"Recall@10    : {recall:.4f}\")\n",
    "print(f\"Precision@10 : {precision:.4f}\")\n",
    "print(f\"NDCG@10      : {ndcg:.4f}\")\n",
    "print(f\"MRR@10       : {mrr:.4f}\")\n",
    "print(f\"Hit@10       : {hit:.4f}\")\n",
    "\n",
    "print(\"=== RecBole モデル評価結果（Top-10）===\")\n",
    "print(f\"Recall@10    : 0.0540\")\n",
    "print(f\"Precision@10 : 0.0621\")\n",
    "print(f\"NDCG@10      : 0.0779\")\n",
    "print(f\"MRR@10       : 0.1579\")\n",
    "print(f\"Hit@10       : 0.3566\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3797a5b4-6650-48cc-b3db-f3780cfa25ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12df90d8-259e-4263-a334-6a45050070aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py310-surprise)",
   "language": "python",
   "name": "py310-surprise"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
